{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf555b1f",
   "metadata": {},
   "source": [
    "#### In this notebook, scraping and retrieval of data from the NBA official stats page will be conducted. \n",
    "\n",
    "All the data is obtained from this site: https://www.nba.com/stats\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce1f8a8e",
   "metadata": {},
   "source": [
    "### 1.0 Data Retrieval through API requests\n",
    "\n",
    "#### 1.1 Playtype Dataset\n",
    "\n",
    "\n",
    "API endpoint URL: https://stats.nba.com/stats/synergyplaytypes?LeagueID=00&PerMode=PerGame&PlayType=Isolation&PlayerOrTeam=T&SeasonType=Regular%20Season&SeasonYear=2024-25&TypeGrouping=offensive\n",
    "\n",
    "From the API URL above, we can observe several parameters that is important for directing to this specific link. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34c564f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "600bfdd3",
   "metadata": {},
   "outputs": [
    {
     "ename": "ConnectionError",
     "evalue": "('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRemoteDisconnected\u001b[39m                        Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\calvin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\urllib3\\connectionpool.py:787\u001b[39m, in \u001b[36mHTTPConnectionPool.urlopen\u001b[39m\u001b[34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[39m\n\u001b[32m    786\u001b[39m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m787\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    788\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    789\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    790\u001b[39m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    791\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    792\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    793\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    794\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    795\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    796\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    797\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    798\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    799\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    800\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    802\u001b[39m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\calvin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\urllib3\\connectionpool.py:534\u001b[39m, in \u001b[36mHTTPConnectionPool._make_request\u001b[39m\u001b[34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[39m\n\u001b[32m    533\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m534\u001b[39m     response = \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    535\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\calvin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\urllib3\\connection.py:516\u001b[39m, in \u001b[36mHTTPConnection.getresponse\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    515\u001b[39m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m516\u001b[39m httplib_response = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    518\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\calvin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\http\\client.py:1411\u001b[39m, in \u001b[36mHTTPConnection.getresponse\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1410\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1411\u001b[39m     \u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1412\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\calvin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\http\\client.py:324\u001b[39m, in \u001b[36mHTTPResponse.begin\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    323\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m324\u001b[39m     version, status, reason = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    325\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m status != CONTINUE:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\calvin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\http\\client.py:293\u001b[39m, in \u001b[36mHTTPResponse._read_status\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    290\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m line:\n\u001b[32m    291\u001b[39m     \u001b[38;5;66;03m# Presumably, the server closed the connection before\u001b[39;00m\n\u001b[32m    292\u001b[39m     \u001b[38;5;66;03m# sending a valid response.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m293\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m RemoteDisconnected(\u001b[33m\"\u001b[39m\u001b[33mRemote end closed connection without\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    294\u001b[39m                              \u001b[33m\"\u001b[39m\u001b[33m response\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    295\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[31mRemoteDisconnected\u001b[39m: Remote end closed connection without response",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mProtocolError\u001b[39m                             Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\calvin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\requests\\adapters.py:667\u001b[39m, in \u001b[36mHTTPAdapter.send\u001b[39m\u001b[34m(self, request, stream, timeout, verify, cert, proxies)\u001b[39m\n\u001b[32m    666\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m667\u001b[39m     resp = \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    668\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    669\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    670\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    671\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    672\u001b[39m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    673\u001b[39m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    674\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    675\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    676\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    677\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    678\u001b[39m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    679\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    681\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\calvin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\urllib3\\connectionpool.py:841\u001b[39m, in \u001b[36mHTTPConnectionPool.urlopen\u001b[39m\u001b[34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[39m\n\u001b[32m    839\u001b[39m     new_e = ProtocolError(\u001b[33m\"\u001b[39m\u001b[33mConnection aborted.\u001b[39m\u001b[33m\"\u001b[39m, new_e)\n\u001b[32m--> \u001b[39m\u001b[32m841\u001b[39m retries = \u001b[43mretries\u001b[49m\u001b[43m.\u001b[49m\u001b[43mincrement\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    842\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnew_e\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_pool\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_stacktrace\u001b[49m\u001b[43m=\u001b[49m\u001b[43msys\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexc_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m    843\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    844\u001b[39m retries.sleep()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\calvin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\urllib3\\util\\retry.py:474\u001b[39m, in \u001b[36mRetry.increment\u001b[39m\u001b[34m(self, method, url, response, error, _pool, _stacktrace)\u001b[39m\n\u001b[32m    473\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m read \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m method \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._is_method_retryable(method):\n\u001b[32m--> \u001b[39m\u001b[32m474\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43merror\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_stacktrace\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    475\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m read \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\calvin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\urllib3\\util\\util.py:38\u001b[39m, in \u001b[36mreraise\u001b[39m\u001b[34m(tp, value, tb)\u001b[39m\n\u001b[32m     37\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m value.__traceback__ \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tb:\n\u001b[32m---> \u001b[39m\u001b[32m38\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m value.with_traceback(tb)\n\u001b[32m     39\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m value\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\calvin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\urllib3\\connectionpool.py:787\u001b[39m, in \u001b[36mHTTPConnectionPool.urlopen\u001b[39m\u001b[34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[39m\n\u001b[32m    786\u001b[39m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m787\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    788\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    789\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    790\u001b[39m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    791\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    792\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    793\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    794\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    795\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    796\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    797\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    798\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    799\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    800\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    802\u001b[39m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\calvin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\urllib3\\connectionpool.py:534\u001b[39m, in \u001b[36mHTTPConnectionPool._make_request\u001b[39m\u001b[34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[39m\n\u001b[32m    533\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m534\u001b[39m     response = \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    535\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\calvin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\urllib3\\connection.py:516\u001b[39m, in \u001b[36mHTTPConnection.getresponse\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    515\u001b[39m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m516\u001b[39m httplib_response = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    518\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\calvin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\http\\client.py:1411\u001b[39m, in \u001b[36mHTTPConnection.getresponse\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1410\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1411\u001b[39m     \u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1412\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\calvin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\http\\client.py:324\u001b[39m, in \u001b[36mHTTPResponse.begin\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    323\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m324\u001b[39m     version, status, reason = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    325\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m status != CONTINUE:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\calvin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\http\\client.py:293\u001b[39m, in \u001b[36mHTTPResponse._read_status\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    290\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m line:\n\u001b[32m    291\u001b[39m     \u001b[38;5;66;03m# Presumably, the server closed the connection before\u001b[39;00m\n\u001b[32m    292\u001b[39m     \u001b[38;5;66;03m# sending a valid response.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m293\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m RemoteDisconnected(\u001b[33m\"\u001b[39m\u001b[33mRemote end closed connection without\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    294\u001b[39m                              \u001b[33m\"\u001b[39m\u001b[33m response\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    295\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[31mProtocolError\u001b[39m: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mConnectionError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 32\u001b[39m\n\u001b[32m     29\u001b[39m params[\u001b[33m'\u001b[39m\u001b[33mPlayType\u001b[39m\u001b[33m'\u001b[39m] = play_type\n\u001b[32m     30\u001b[39m params[\u001b[33m'\u001b[39m\u001b[33mSeasonType\u001b[39m\u001b[33m'\u001b[39m] = season_type\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m response = \u001b[43mrequests\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m#Python’s requests library takes your params dictionary \u001b[39;00m\n\u001b[32m     33\u001b[39m \u001b[38;5;66;03m#and appends it to the URL like a query string.\u001b[39;00m\n\u001b[32m     37\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m response.status_code == \u001b[32m200\u001b[39m: \u001b[38;5;66;03m#if http request was successful \u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\calvin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\requests\\api.py:73\u001b[39m, in \u001b[36mget\u001b[39m\u001b[34m(url, params, **kwargs)\u001b[39m\n\u001b[32m     62\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget\u001b[39m(url, params=\u001b[38;5;28;01mNone\u001b[39;00m, **kwargs):\n\u001b[32m     63\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[32m     64\u001b[39m \n\u001b[32m     65\u001b[39m \u001b[33;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     70\u001b[39m \u001b[33;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[32m     71\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m73\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mget\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\calvin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\requests\\api.py:59\u001b[39m, in \u001b[36mrequest\u001b[39m\u001b[34m(method, url, **kwargs)\u001b[39m\n\u001b[32m     55\u001b[39m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[32m     56\u001b[39m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[32m     57\u001b[39m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m sessions.Session() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\calvin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\requests\\sessions.py:589\u001b[39m, in \u001b[36mSession.request\u001b[39m\u001b[34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[39m\n\u001b[32m    584\u001b[39m send_kwargs = {\n\u001b[32m    585\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtimeout\u001b[39m\u001b[33m\"\u001b[39m: timeout,\n\u001b[32m    586\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mallow_redirects\u001b[39m\u001b[33m\"\u001b[39m: allow_redirects,\n\u001b[32m    587\u001b[39m }\n\u001b[32m    588\u001b[39m send_kwargs.update(settings)\n\u001b[32m--> \u001b[39m\u001b[32m589\u001b[39m resp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    591\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\calvin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\requests\\sessions.py:703\u001b[39m, in \u001b[36mSession.send\u001b[39m\u001b[34m(self, request, **kwargs)\u001b[39m\n\u001b[32m    700\u001b[39m start = preferred_clock()\n\u001b[32m    702\u001b[39m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m703\u001b[39m r = \u001b[43madapter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    705\u001b[39m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[32m    706\u001b[39m elapsed = preferred_clock() - start\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\calvin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\requests\\adapters.py:682\u001b[39m, in \u001b[36mHTTPAdapter.send\u001b[39m\u001b[34m(self, request, stream, timeout, verify, cert, proxies)\u001b[39m\n\u001b[32m    667\u001b[39m     resp = conn.urlopen(\n\u001b[32m    668\u001b[39m         method=request.method,\n\u001b[32m    669\u001b[39m         url=url,\n\u001b[32m   (...)\u001b[39m\u001b[32m    678\u001b[39m         chunked=chunked,\n\u001b[32m    679\u001b[39m     )\n\u001b[32m    681\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m--> \u001b[39m\u001b[32m682\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request=request)\n\u001b[32m    684\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m MaxRetryError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    685\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e.reason, ConnectTimeoutError):\n\u001b[32m    686\u001b[39m         \u001b[38;5;66;03m# TODO: Remove this in 3.0.0: see #2811\u001b[39;00m\n",
      "\u001b[31mConnectionError\u001b[39m: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "url = \"https://stats.nba.com/stats/synergyplaytypes\" #base api URL\n",
    "\n",
    "#variable parameters is PlayType and Season Type\n",
    "\n",
    "base_params = {\"LeagueID\":\"00\",\n",
    "                \"PerMode\":\"PerGame\",\n",
    "                \"PlayerOrTeam\":\"T\",\n",
    "                \"SeasonYear\":\"2024-25\",\n",
    "                \"TypeGrouping\":\"offensive\"}\n",
    "\n",
    "playtype = [\"Isolation\",\"Transition\",\"PRBallHandler\",\"PRRollman\",\"Postup\",\"Spotup\",\n",
    "            \"Handoff\",\"Cut\",\"OffScreen\",\"OffRebound\",\"Misc\"]\n",
    "\n",
    "seasontype = [\"Playoffs\",\"Regular Season\"]\n",
    "\n",
    "\n",
    "headers = {\n",
    "    \"User-Agent\":\"Mozzila/5.0\",\n",
    "    \"Referer\":\"https://www.nba.com/\"\n",
    "}\n",
    "\n",
    "playoffs_data = []\n",
    "reg_szn_data = []\n",
    "for season_type in seasontype:\n",
    "\n",
    "    for play_type in playtype:\n",
    "\n",
    "        params = base_params.copy()\n",
    "        params['PlayType'] = play_type\n",
    "        params['SeasonType'] = season_type\n",
    "\n",
    "        response = requests.get(url,headers = headers, params = params) #Python’s requests library takes your params dictionary \n",
    "        #and appends it to the URL like a query string.\n",
    "\n",
    "\n",
    "\n",
    "        if response.status_code == 200: #if http request was successful \n",
    "            data = response.json()\n",
    "            headers_ = data[\"resultSets\"][0]['headers'] #data['resultSets'] returns a list of tables. (usually only 1 table)\n",
    "            #we need to grab the first table from that list of table, so [0] will access the actual table\n",
    "            #'headers' specifies the column we want to retrieve\n",
    "            rows = data[\"resultSets\"][0]['rowSet']\n",
    "\n",
    "            df = pd.DataFrame(rows,columns=headers_)\n",
    "            if season_type == \"Playoffs\":\n",
    "                playoffs_data.append(df) # all_data is a list of DataFrames: [Isolation ... , Transition..., etc]\n",
    "            else:\n",
    "                reg_szn_data.append(df)\n",
    "        else:\n",
    "            print(\"HTTP Request could not be parsed\")\n",
    "\n",
    "        \n",
    "        time.sleep(1) #pauses for 1 second to prevent getting rate-limited or blocked by the nba site\n",
    "\n",
    "playoffs_df = pd.concat(playoffs_data,ignore_index = True) #pd.concat will stack all those DataFrame in all_data row_wise \n",
    "reg_szn_df = pd.concat(reg_szn_data,ignore_index = True)\n",
    "\n",
    "#ignore_index resets row indices to be continuous from 0 \n",
    "\n",
    "# playoffs_df.to_csv(r\"C:\\Users\\calvin\\Documents\\python\\NBA data analysis project\\nba analysis csv files\\nba_playoffs_playtype_2024-2025.csv\",index = False)\n",
    "# reg_szn_df.to_csv(r\"C:\\Users\\calvin\\Documents\\python\\NBA data analysis project\\nba analysis csv files\\nba_regular_season_playtype_2024-2025.csv\",index = False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc4b9b3c",
   "metadata": {},
   "source": [
    "From observing the API endpoint URLs, we notice that only Playtype stats is provided by synergy.\n",
    "\n",
    "The rest of the stats have a similar endpoint URL beginning with https://stats.nba.com/stats/\n",
    "\n",
    "API endpoint URL for Clutch Stats: https://stats.nba.com/stats/leaguedashteamclutch?AheadBehind=Ahead%20or%20Behind&ClutchTime=Last%205%20Minutes&College=&Conference=&Country=&DateFrom=&DateTo=&Division=&DraftPick=&DraftYear=&GameScope=&GameSegment=&Height=&ISTRound=&LastNGames=0&LeagueID=00&Location=&MeasureType=Base&Month=0&OpponentTeamID=0&Outcome=&PORound=0&PaceAdjust=N&PerMode=PerGame&Period=0&PlayerExperience=&PlayerPosition=&PlusMinus=N&PointDiff=5&Rank=N&Season=2024-25&SeasonSegment=&SeasonType=Playoffs&ShotClockRange=&StarterBench=&TeamID=0&VsConference=&VsDivision=&Weight=\n",
    "\n",
    "URL for Tracking Drives: https://stats.nba.com/stats/leaguedashptstats?College=&Conference=&Country=&DateFrom=&DateTo=&Division=&DraftPick=&DraftYear=&GameScope=&Height=&ISTRound=&LastNGames=0&LeagueID=00&Location=&Month=0&OpponentTeamID=0&Outcome=&PORound=0&PerMode=PerGame&PlayerExperience=&PlayerOrTeam=Team&PlayerPosition=&PtMeasureType=Drives&Season=2024-25&SeasonSegment=&SeasonType=Playoffs&StarterBench=&TeamID=0&VsConference=&VsDivision=&Weight=\n",
    "\n",
    "\n",
    "\n",
    "We can do it manually, or we can use selenium-wire to automate the retrieval of all these Request URLs. **(nvm, selenium doesnt automate it. i will do what i did for playtype and repeat for the other categories)**\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e165ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://stats.nba.com/stats/leaguedashteamclutch?AheadBehind=Ahead%20or%20Behind&ClutchTime=Last%205%20Minutes&College=&Conference=&Country=&DateFrom=&DateTo=&Division=&DraftPick=&DraftYear=&GameScope=&GameSegment=&Height=&ISTRound=&LastNGames=0&LeagueID=00&Location=&MeasureType=Base&Month=0&OpponentTeamID=0&Outcome=&PORound=0&PaceAdjust=N&PerMode=PerGame&Period=0&PlayerExperience=&PlayerPosition=&PlusMinus=N&PointDiff=5&Rank=N&Season=2024-25&SeasonSegment=&SeasonType=Playoffs&ShotClockRange=&StarterBench=&TeamID=0&VsConference=&VsDivision=&Weight=\n"
     ]
    }
   ],
   "source": [
    "from seleniumwire import webdriver\n",
    "\n",
    "#start browser\n",
    "options = webdriver.ChromeOptions()\n",
    "driver = webdriver.Chrome(options=options)\n",
    "\n",
    "#load webpage\n",
    "driver.get(\"https://www.nba.com/stats/teams/clutch-traditional\")\n",
    "\n",
    "\n",
    "time.sleep(5) #wait a few seconds before making requests\n",
    "\n",
    "for request in driver.requests:\n",
    "    if request.response and \"stats.nba.com\" in request.url:\n",
    "        print(request.url)\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "183f2e1c",
   "metadata": {},
   "source": [
    "Through the manual way, we will have to find out the base_params that we are interested in, and we find these params by observing the URL. There may be some unnecessary params that are empty that we can ignore. \n",
    "\n",
    "#### 1.2 Clutch Stats Dataset\n",
    "\n",
    "\n",
    "Lets try to do Clutch Stats as a function\n",
    "\n",
    "API URL CLutch Stats: https://stats.nba.com/stats/leaguedashteamclutch?AheadBehind=Ahead%20or%20Behind&ClutchTime=Last%205%20Minutes&College=&Conference=&Country=&DateFrom=&DateTo=&Division=&DraftPick=&DraftYear=&GameScope=&GameSegment=&Height=&ISTRound=&LastNGames=0&LeagueID=00&Location=&MeasureType=Base&Month=0&OpponentTeamID=0&Outcome=&PORound=0&PaceAdjust=N&PerMode=PerGame&Period=0&PlayerExperience=&PlayerPosition=&PlusMinus=N&PointDiff=5&Rank=N&Season=2024-25&SeasonSegment=&SeasonType=Playoffs&ShotClockRange=&StarterBench=&TeamID=0&VsConference=&VsDivision=&Weight=\n",
    "\n",
    "\n",
    "When we actually attempt to find the base params from the URL, we can see that it can be abit time consuming to manually analyse the link. Another easier way is to F12 on the webpage > Network > Fetch/XHR > Click on the API endpoint URL > Payload\n",
    "\n",
    "Here, we can see the query string parameters and its values. (we still have to derive which is base_params and which is variable params ourselves). We can ignore empty parameters, parameters with \"N\", parameters with \"0\"\n",
    "\n",
    "For Clutch Stats, we can see that variable params will be MeasureType and SeasonType (and Season if we want to get multiple seasons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44d20b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clutch_stats():\n",
    "    url = \"https://stats.nba.com/stats/leaguedashteamclutch\"\n",
    "    base_param = {\n",
    "        \"AheadBehind\": \"Ahead or Behind\",\n",
    "        \"ClutchTime\": \"Last 5 Minutes\",\n",
    "        \"LastNGames\": \"0\",\n",
    "        \"LeagueID\": \"00\",\n",
    "        \"PerMode\": \"PerGame\",\n",
    "        \"PointDiff\": \"5\",\n",
    "        \"Season\": \"2024-25\",\n",
    "        \"SeasonSegment\": \"\",\n",
    "        \"DateFrom\": \"\",\n",
    "        \"DateTo\": \"\",\n",
    "        \"GameScope\": \"\",\n",
    "        \"PlayerExperience\": \"\",\n",
    "        \"PlayerPosition\": \"\",\n",
    "        \"StarterBench\": \"\",\n",
    "        \"Conference\": \"\",\n",
    "        \"Division\": \"\",\n",
    "        \"GameSegment\": \"\",\n",
    "        \"Location\": \"\",\n",
    "        \"MeasureType\": \"Base\",\n",
    "        \"Month\": \"0\",\n",
    "        \"OpponentTeamID\": \"0\",\n",
    "        \"Outcome\": \"\",\n",
    "        \"PaceAdjust\": \"N\",\n",
    "        \"PlusMinus\": \"N\",\n",
    "        \"Period\": \"0\",\n",
    "        \"Rank\": \"N\",\n",
    "        \"SeasonType\": \"Regular Season\",\n",
    "        \"ShotClockRange\": \"\",\n",
    "        \"TeamID\": \"0\",\n",
    "        \"TwoWay\": \"0\",\n",
    "        \"VsConference\": \"\",\n",
    "        \"VsDivision\": \"\"\n",
    "    }\n",
    "    measuretype = ['Base','Advanced','Four Factors','Misc','Scoring','Opponent'] #Note, Opponent is to see opponent's clutch stats against current team\n",
    "\n",
    "    seasontype = ['Playoffs','Regular Season']\n",
    "\n",
    "    headers = {\n",
    "        \"Host\": \"stats.nba.com\",\n",
    "        \"Connection\": \"keep-alive\",\n",
    "        \"Accept\": \"application/json, text/plain, */*\",\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) \"\n",
    "                    \"AppleWebKit/537.36 (KHTML, like Gecko) \"\n",
    "                    \"Chrome/138.0.0.0 Safari/537.36\",\n",
    "        \"Referer\": \"https://www.nba.com/stats/teams/clutch-traditional/\",\n",
    "        \"Origin\": \"https://www.nba.com\",\n",
    "        \"Accept-Encoding\": \"gzip, deflate, br\",\n",
    "        \"Accept-Language\": \"en-US,en;q=0.9\"\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "    playoffs_data = []\n",
    "    reg_szn_data = []\n",
    "    for season_type in seasontype:\n",
    "\n",
    "        for measure_type in measuretype:\n",
    "\n",
    "            param = base_param.copy()\n",
    "            param['MeasureType'] = measure_type\n",
    "            param['SeasonType'] = season_type\n",
    "\n",
    "            response = requests.get(url,headers = headers, params = param) #Python’s requests library takes your params dictionary \n",
    "            #and appends it to the URL like a query string.\n",
    "\n",
    "\n",
    "\n",
    "            if response.status_code == 200: #if http request was successful \n",
    "                data = response.json()\n",
    "                headers_ = data[\"resultSets\"][0]['headers'] #data['resultSets'] returns a list of tables. (usually only 1 table)\n",
    "                #we need to grab the first table from that list of table, so [0] will access the actual table\n",
    "                #'headers' specifies the column we want to retrieve\n",
    "                rows = data[\"resultSets\"][0]['rowSet']\n",
    "\n",
    "                df = pd.DataFrame(rows,columns=headers_)\n",
    "                if season_type == \"Playoffs\":\n",
    "                    playoffs_data.append(df) # all_data is a list of DataFrames: [Isolation ... , Transition..., etc]\n",
    "                else:\n",
    "                    reg_szn_data.append(df)\n",
    "            else:\n",
    "                print(f\"❌ Request failed | {season_type=} | {measure_type=} | Status code: {response.status_code}\")\n",
    "\n",
    "            \n",
    "            time.sleep(1) #pauses for 1 second to prevent getting rate-limited or blocked by the nba site\n",
    "\n",
    "#for Clutch Stats, we cannot use pd.concat unlike for Playtype. This is because the headers for each column for Playtype is the same\n",
    "#for all variable parameters, while it is all different for Clutch Stats. \n",
    "#Therefore, we have to use .concat, and introduce a extra column labelling the variable parameter for that\n",
    "\n",
    "    playoffs_df = pd.concat(playoffs_data,axis = 1) \n",
    "    reg_szn_df = pd.concat(reg_szn_data,axis = 1)\n",
    "\n",
    "\n",
    "    return playoffs_df,reg_szn_df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a34c8b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clutch_stats():\n",
    "    url = \"https://stats.nba.com/stats/leaguedashteamclutch\"\n",
    "    base_param = {\n",
    "        \"AheadBehind\": \"Ahead or Behind\",\n",
    "        \"ClutchTime\": \"Last 5 Minutes\",\n",
    "        \"LastNGames\": \"0\",\n",
    "        \"LeagueID\": \"00\",\n",
    "        \"PerMode\": \"PerGame\",\n",
    "        \"PointDiff\": \"5\",\n",
    "        \"Season\": \"2024-25\",\n",
    "        \"SeasonSegment\": \"\",\n",
    "        \"DateFrom\": \"\",\n",
    "        \"DateTo\": \"\",\n",
    "        \"GameScope\": \"\",\n",
    "        \"PlayerExperience\": \"\",\n",
    "        \"PlayerPosition\": \"\",\n",
    "        \"StarterBench\": \"\",\n",
    "        \"Conference\": \"\",\n",
    "        \"Division\": \"\",\n",
    "        \"GameSegment\": \"\",\n",
    "        \"Location\": \"\",\n",
    "        \"MeasureType\": \"Base\",\n",
    "        \"Month\": \"0\",\n",
    "        \"OpponentTeamID\": \"0\",\n",
    "        \"Outcome\": \"\",\n",
    "        \"PaceAdjust\": \"N\",\n",
    "        \"PlusMinus\": \"N\",\n",
    "        \"Period\": \"0\",\n",
    "        \"Rank\": \"N\",\n",
    "        \"SeasonType\": \"Regular Season\",\n",
    "        \"ShotClockRange\": \"\",\n",
    "        \"TeamID\": \"0\",\n",
    "        \"TwoWay\": \"0\",\n",
    "        \"VsConference\": \"\",\n",
    "        \"VsDivision\": \"\"\n",
    "    }\n",
    "    measuretype = ['Base','Advanced','Four Factors','Misc','Scoring','Opponent'] #Note, Opponent is to see opponent's clutch stats against current team\n",
    "\n",
    "    seasontype = ['Playoffs','Regular Season']\n",
    "\n",
    "    headers = {\n",
    "        \"Host\": \"stats.nba.com\",\n",
    "        \"Connection\": \"keep-alive\",\n",
    "        \"Accept\": \"application/json, text/plain, */*\",\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) \"\n",
    "                    \"AppleWebKit/537.36 (KHTML, like Gecko) \"\n",
    "                    \"Chrome/138.0.0.0 Safari/537.36\",\n",
    "        \"Referer\": \"https://www.nba.com/stats/teams/clutch-traditional/\",\n",
    "        \"Origin\": \"https://www.nba.com\",\n",
    "        \"Accept-Encoding\": \"gzip, deflate, br\",\n",
    "        \"Accept-Language\": \"en-US,en;q=0.9\"\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "    playoffs_data = []\n",
    "    reg_szn_data = []\n",
    "    combined_df_playoffs = pd.DataFrame()\n",
    "    combined_df_reg = pd.DataFrame()\n",
    "    for season_type in seasontype:\n",
    "\n",
    "        for measure_type in measuretype:\n",
    "\n",
    "            param = base_param.copy()\n",
    "            param['MeasureType'] = measure_type\n",
    "            param['SeasonType'] = season_type\n",
    "\n",
    "            response = requests.get(url,headers = headers, params = param) #Python’s requests library takes your params dictionary \n",
    "            #and appends it to the URL like a query string.\n",
    "\n",
    "\n",
    "\n",
    "            if response.status_code == 200: #if http request was successful \n",
    "                data = response.json()\n",
    "                headers_ = data[\"resultSets\"][0]['headers'] #data['resultSets'] returns a list of tables. (usually only 1 table)\n",
    "                #we need to grab the first table from that list of table, so [0] will access the actual table\n",
    "                #'headers' specifies the column we want to retrieve\n",
    "                rows = data[\"resultSets\"][0]['rowSet']\n",
    "\n",
    "                df = pd.DataFrame(rows,columns=headers_)\n",
    "                if season_type == \"Playoffs\":\n",
    "                    # playoffs_data.append(df) # all_data is a list of DataFrames: [Isolation ... , Transition..., etc]\n",
    "                    df = df.add_suffix(f'_{measure_type}') #we add suffix because each variable param may contain the same header\n",
    "                    #suffix of each measure_type will indicate which param the header belongs to \n",
    "                    df = df.rename(columns = {f\"TEAM_NAME_{measure_type}\" : \"TEAM_NAME\"}) #however, we want the TEAM_NAME to be constant, as we want to merge on this\n",
    "                    if combined_df_playoffs.empty:\n",
    "                        combined_df_playoffs = df\n",
    "                    \n",
    "                    else:\n",
    "                        df = df.drop(columns=[f'TEAM_ID_{measure_type}'])\n",
    "                        combined_df_playoffs = pd.merge(combined_df_playoffs,df,on=\"TEAM_NAME\",how=\"outer\") \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                else:\n",
    "                    # reg_szn_data.append(df)\n",
    "                    df = df.add_suffix(f'_{measure_type}')\n",
    "                    df = df.rename(columns = {f\"TEAM_NAME_{measure_type}\" : \"TEAM_NAME\"})\n",
    "                    if combined_df_reg.empty:\n",
    "                        combined_df_reg = df\n",
    "                    else:\n",
    "                        df = df.drop(columns=[f'TEAM_ID_{measure_type}'])\n",
    "\n",
    "                        combined_df_reg = pd.merge(combined_df_reg,df,on=\"TEAM_NAME\",how=\"outer\")\n",
    "            else:\n",
    "                print(f\"❌ Request failed | {season_type=} | {measure_type=} | Status code: {response.status_code}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                \n",
    "            time.sleep(1) #pauses for 1 second to prevent getting rate-limited or blocked by the nba site\n",
    "\n",
    "#for Clutch Stats, we cannot use pd.concat unlike for Playtype. This is because the headers for each column for Playtype is the same\n",
    "#for all variable parameters, while it is all different for Clutch Stats. \n",
    "#Therefore, we have to use .concat, and introduce a extra column labelling the variable parameter for that group of data.\n",
    "\n",
    "    # playoffs_df = pd.concat(playoffs_data,ignore_index = True) \n",
    "    # reg_szn_df = pd.concat(reg_szn_data,ignore_index = True)\n",
    "\n",
    "\n",
    "    return combined_df_playoffs,combined_df_reg\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf9e2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "clutch_playoffs,clutch_regszn = clutch_stats()\n",
    "\n",
    "clutch_playoffs.to_csv(r\"C:\\Users\\calvin\\Documents\\python\\NBA data analysis project\\nba analysis csv files\\nba_playoffs_clutch_2024-2025.csv\",index = False)\n",
    "clutch_regszn.to_csv(r\"C:\\Users\\calvin\\Documents\\python\\NBA data analysis project\\nba analysis csv files\\nba_regular_season_clutch_2024-2025.csv\",index = False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fd009fd",
   "metadata": {},
   "source": [
    "First attempt of running the clutch_stats() function and we get this error:\n",
    "\n",
    "\n",
    "\n",
    "❌ Request failed | season_type='Playoffs' | measure_type='Base' | Status code: 500\n",
    "❌ Request failed | season_type='Playoffs' | measure_type='Advanced' | Status code: 500\n",
    "❌ Request failed | season_type='Playoffs' | measure_type='Four Factors' | Status code: 500\n",
    "❌ Request failed | season_type='Playoffs' | measure_type='Misc' | Status code: 500\n",
    "❌ Request failed | season_type='Playoffs' | measure_type='Scoring' | Status code: 500\n",
    "❌ Request failed | season_type='Playoffs' | measure_type='Opponent' | Status code: 500\n",
    "❌ Request failed | season_type='Regular Season' | measure_type='Base' | Status code: 500\n",
    "❌ Request failed | season_type='Regular Season' | measure_type='Advanced' | Status code: 500\n",
    "❌ Request failed | season_type='Regular Season' | measure_type='Four Factors' | Status code: 500\n",
    "❌ Request failed | season_type='Regular Season' | measure_type='Misc' | Status code: 500\n",
    "❌ Request failed | season_type='Regular Season' | measure_type='Scoring' | Status code: 500\n",
    "❌ Request failed | season_type='Regular Season' | measure_type='Opponent' | Status code: 500\n",
    "\n",
    "#### Status code 500 comes from the requests.status_code, indicating that there might be an issue with our headers, such that the NBA site is blocking it. \n",
    "\n",
    "#### **As it turns out, the headers were not the issue, but instead, the NBA Stats API page required that all params in the request URL be defined, even if 0, N or empty.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fe538f6",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5230f2ec",
   "metadata": {},
   "source": [
    "#### 1.3 Tracking Stats \n",
    "\n",
    "The \"Tracking\" category measures the attempts, efficiency and relevant stats for that particular action or or outcome, such as \"Drives\", \"Pullup Shooting\", \"Paint Touches\", etc. \n",
    "\n",
    "sample API URL: https://stats.nba.com/stats/leaguedashptstats?College=&Conference=&Country=&DateFrom=&DateTo=&Division=&DraftPick=&DraftYear=&GameScope=&Height=&ISTRound=&LastNGames=0&LeagueID=00&Location=&Month=0&OpponentTeamID=0&Outcome=&PORound=0&PerMode=PerGame&PlayerExperience=&PlayerOrTeam=Team&PlayerPosition=&PtMeasureType=Drives&Season=2024-25&SeasonSegment=&SeasonType=Regular%20Season&StarterBench=&TeamID=0&VsConference=&VsDivision=&Weight=\n",
    "\n",
    "\n",
    "\n",
    "Variable parameters are SeasonType and PtMeasureType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "44030a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tracking_stats():\n",
    "    url = \"https://stats.nba.com/stats/leaguedashptstats\"\n",
    "    base_params = {\n",
    "        \"College\": \"\",\n",
    "        \"Conference\": \"\",\n",
    "        \"Country\":\"\",\n",
    "        \"DateFrom\":\"\",\n",
    "        \"DateTo\":\"\",\n",
    "        \"Division\":\"\",\n",
    "        \"DraftPick\":\"\",\n",
    "        \"DraftYear\":\"\",\n",
    "        \"GameScope\":\"\",\n",
    "        \"Height\":\"\",\n",
    "        \"ISTRound\":\"\",\n",
    "        \"LastNGames\":\"0\",\n",
    "        \"LeagueID\":\"00\",\n",
    "        \"Location\":\"\",\n",
    "        \"Month\":\"0\",\n",
    "        \"OpponentTeamID\":\"0\",\n",
    "        \"Outcome\":\"\",\n",
    "        \"PORound\":\"0\",\n",
    "        \"PerMode\":\"PerGame\",\n",
    "        \"PlayerExperience\":\"\",\n",
    "        \"PlayerOrTeam\":\"Team\",\n",
    "        \"PlayerPosition\":\"\",\n",
    "        \"Season\":\"2024-25\",\n",
    "        \"TeamID\":\"0\",\n",
    "    }\n",
    "    measuretype = ['Drives','Defense','CatchShoot','Passing','Possessions','PullUpShot','Rebounding',\n",
    "                   'Efficiency','SpeedDistance','ElbowTouch','PostTouch','PaintTouch']\n",
    "    seasontype = ['Playoffs','Regular Season'] \n",
    "    #Possessions = Touches ##Rebounding, Offensive Rebounding and Defensive Rebounding share the same API URL, unsure how to separate them. \n",
    "\n",
    "    headers = {\n",
    "        \"Host\": \"stats.nba.com\",\n",
    "        \"Connection\": \"keep-alive\",\n",
    "        \"Accept\": \"application/json, text/plain, */*\",\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) \"\n",
    "                    \"AppleWebKit/537.36 (KHTML, like Gecko) \"\n",
    "                    \"Chrome/138.0.0.0 Safari/537.36\",\n",
    "        \"Referer\": \"https://www.nba.com/stats/teams/drives\",\n",
    "        \"Origin\": \"https://www.nba.com\",\n",
    "        \"Accept-Encoding\": \"gzip, deflate, br\",\n",
    "        \"Accept-Language\": \"en-US,en;q=0.9\"\n",
    "    }\n",
    "\n",
    "    playoff_tracking = []\n",
    "    RS_tracking = []\n",
    "    combined_playoff_tracking = pd.DataFrame\n",
    "    combined_RS_tracking = pd.DataFrame\n",
    "    for season_type in seasontype:\n",
    "        for measure_type in measuretype:\n",
    "            param = base_params.copy()\n",
    "            param['PTMeasureType'] = measure_type\n",
    "            param['SeasonType'] = season_type\n",
    "\n",
    "\n",
    "            response = requests.get(url,params=param,headers=headers)\n",
    "\n",
    "            if response.status_code == 200:\n",
    "                data = response.json()\n",
    "                rows = data['resultSets'][0]['rowSet']\n",
    "                headers_ = data['resultSets'][0]['headers']\n",
    "                \n",
    "                df = pd.DataFrame(rows,columns = headers_)\n",
    "\n",
    "\n",
    "                df = df.add_suffix(f\"_{measure_type}\")\n",
    "                df = df.rename(columns = {f\"TEAM_NAME_{measure_type}\":\"TEAM_NAME\"})\n",
    "\n",
    "                if season_type == \"Playoffs\":\n",
    "                    if combined_playoff_tracking.empty:\n",
    "                        combined_playoff_tracking = df\n",
    "                    else:\n",
    "                        df = df.drop(columns=[f\"TEAM_ID_{measure_type}\",f\"TEAM_ABBREVIATION_{measure_type}\"])\n",
    "\n",
    "                        combined_playoff_tracking = pd.merge(combined_playoff_tracking,df,on = \"TEAM_NAME\",how = \"outer\")\n",
    "                else:\n",
    "                    if combined_RS_tracking.empty:\n",
    "                        combined_RS_tracking = df\n",
    "                    else:\n",
    "                        df = df.drop(columns=[f\"TEAM_ID_{measure_type}\",f\"TEAM_ABBREVIATION_{measure_type}\"])\n",
    "\n",
    "                        combined_RS_tracking = pd.merge(combined_RS_tracking,df,on = \"TEAM_NAME\",how = \"outer\")\n",
    "\n",
    "\n",
    "            else:\n",
    "                print(f\"Print Failed, response status code {response.status_code}\")\n",
    "\n",
    "            time.sleep(1)\n",
    "\n",
    "    return combined_playoff_tracking,combined_RS_tracking\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e5376f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tracking_playoffs,tracking_RS = tracking_stats()\n",
    "\n",
    "tracking_playoffs.to_csv(r\"C:\\Users\\calvin\\Documents\\python\\NBA data analysis project\\nba analysis csv files\\nba_playoffs_tracking_2024-2025.csv\",index = False)\n",
    "tracking_RS.to_csv(r\"C:\\Users\\calvin\\Documents\\python\\NBA data analysis project\\nba analysis csv files\\nba_regular_season_tracking_2024-2025.csv\",index = False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69e8a92b",
   "metadata": {},
   "source": [
    "#### 1.4 General Stats Version 1\n",
    "\n",
    "\n",
    "https://stats.nba.com/stats/leaguedashteamstats?Conference=&DateFrom=&DateTo=&Division=&GameScope=&GameSegment=&Height=&ISTRound=&LastNGames=0&LeagueID=00&Location=&MeasureType=Base&Month=0&OpponentTeamID=0&Outcome=&PORound=0&PaceAdjust=N&PerMode=PerGame&Period=0&PlayerExperience=&PlayerPosition=&PlusMinus=N&Rank=N&Season=2024-25&SeasonSegment=&SeasonType=Playoffs&ShotClockRange=&StarterBench=&TeamID=0&TwoWay=0&VsConference=&VsDivision="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f2a884",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seasons(start_year,current_year):\n",
    "    #this function is to generate a list of seasons \"2024-25\",\"2023-24\",\"2022-23\", etc to pass into our main function\n",
    "    #stats are tracked starting from 1996-97 season\n",
    "    #current_year = \"2025\"\n",
    "    base = int(start_year)\n",
    "    num_years = int(current_year) - base \n",
    "    year_list = []\n",
    "    for i in range(num_years):\n",
    "        season = [f'{base+i}',f'{base+i+1}']\n",
    "        sliced = season[0] + '-' + season[1][2:4]\n",
    "        year_list.append(sliced)\n",
    "    return year_list\n",
    "\n",
    "\n",
    "def traditional_stats():\n",
    "    url = \"https://stats.nba.com/stats/leaguedashteamstats\"\n",
    "    base_params = {\n",
    "        \"Conference\": \"\",\n",
    "        \"DateFrom\":\"\",\n",
    "        \"DateTo\":\"\",\n",
    "        \"Division\":\"\",\n",
    "        \"GameScope\":\"\",\n",
    "        \"GameSegment\":\"\",\n",
    "        \"Height\":\"\",\n",
    "        \"ISTRound\":\"\",\n",
    "        \"LastNGames\":\"0\",\n",
    "        \"LeagueID\":\"00\",\n",
    "        \"Location\":\"\",\n",
    "        \"Month\":\"0\",\n",
    "        \"OpponentTeamID\":\"0\",\n",
    "        \"Outcome\":\"\",\n",
    "        \"PORound\":\"0\",\n",
    "        \"PaceAdjust\":\"N\",\n",
    "        \"PerMode\":\"PerGame\",\n",
    "        \"Period\":\"0\",\n",
    "        \"PlayerExperience\":\"\",\n",
    "        \"PlayerPosition\":\"\",\n",
    "        \"PlusMinus\":\"N\",\n",
    "        \"Rank\":\"N\",\n",
    "        \"Season\":\"2024-25\",\n",
    "        \"SeasonSegment\":\"\",\n",
    "        \"ShotClockRange\":\"\",\n",
    "        \"StarterBench\":\"\",\n",
    "        \"TeamID\":\"0\",\n",
    "        \"TwoWay\":\"\",\n",
    "        \"VsConference\":\"\",\n",
    "        \"VsDivision\":\"\",\n",
    "    }\n",
    "    measuretype = ['Base','Advanced','Four Factors','Misc','Scoring','Opponent','Defense',\n",
    "                   'Violations']\n",
    "    seasontype = ['Playoffs','Regular Season'] \n",
    "    cur_seasons = seasons('2010','2025')\n",
    "    seasonsegment = ['Pre All-Star','Post All-Star']\n",
    "    #Possessions = Touches ##Rebounding, Offensive Rebounding and Defensive Rebounding share the same API URL, unsure how to separate them. \n",
    "\n",
    "    headers = {\n",
    "        \"Host\": \"stats.nba.com\",\n",
    "        \"Connection\": \"keep-alive\",\n",
    "        \"Accept\": \"application/json, text/plain, */*\",\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) \"\n",
    "                    \"AppleWebKit/537.36 (KHTML, like Gecko) \"\n",
    "                    \"Chrome/138.0.0.0 Safari/537.36\",\n",
    "        \"Referer\": \"https://www.nba.com/stats/teams/traditional\",\n",
    "        \"Origin\": \"https://www.nba.com\",\n",
    "        \"Accept-Encoding\": \"gzip, deflate, br\",\n",
    "        \"Accept-Language\": \"en-US,en;q=0.9\"\n",
    "    }\n",
    "\n",
    "    print(cur_seasons)\n",
    "    print(len(cur_seasons))\n",
    "    playoff_list = []\n",
    "    rs_list = []\n",
    "    for season_var in cur_seasons: #looping through all seasons from the seasons function. \n",
    "        combined_playoff_df = pd.DataFrame() #reinitialising empty df for each season\n",
    "        combined_RS_df = pd.DataFrame()\n",
    "        for season_type in seasontype:\n",
    "            for measure_type in measuretype:\n",
    "                param = base_params.copy()\n",
    "                param['MeasureType'] = measure_type #the column name MUST match the header in the API endpoint\n",
    "                param['SeasonType'] = season_type\n",
    "                param['Season'] = season_var\n",
    "\n",
    "                response = requests.get(url,params=param,headers=headers) #utilising .get to combine url, params and headers to retrieve information\n",
    "\n",
    "                if response.status_code == 200: #status code 200: http approved the request. other status code can look online\n",
    "                    data = response.json() #to view this data, go to the api endpoint url > response to see the json data \n",
    "                    rows = data['resultSets'][0]['rowSet'] #from the json data, we extract the rows and columns \n",
    "                    headers_ = data['resultSets'][0]['headers']\n",
    "                    \n",
    "                    df = pd.DataFrame(rows,columns = headers_)\n",
    "                    df = df.add_suffix(f\"_{measure_type}\") #adds a suffix to all headers in the dataframe > all headers will have _measuretype\n",
    "                    df = df.rename(columns = {f\"TEAM_NAME_{measure_type}\":\"TEAM_NAME\"}) #maintain the teamname header as the common header, since we will merge on this header\n",
    "\n",
    "                    if season_type == \"Playoffs\":\n",
    "                        if combined_playoff_df.empty:\n",
    "                            combined_playoff_df = df\n",
    "                        else:\n",
    "                            df = df.drop(columns=[f'TEAM_ID_{measure_type}',f'GP_{measure_type}',f'W_{measure_type}',f'L_{measure_type}',f'W_PCT_{measure_type}'])\n",
    "                            #drop duplicate columns \n",
    "                            combined_playoff_df = pd.merge(combined_playoff_df,df,on = \"TEAM_NAME\",how = \"outer\")\n",
    "                            \n",
    "                    else:\n",
    "                        if combined_RS_df.empty:\n",
    "                            combined_RS_df = df\n",
    "                        else:\n",
    "                            df = df.drop(columns=[f'TEAM_ID_{measure_type}',f'GP_{measure_type}',f'W_{measure_type}',f'L_{measure_type}',f'W_PCT_{measure_type}'])\n",
    "                            combined_RS_df = pd.merge(combined_RS_df,df,on = \"TEAM_NAME\",how = \"outer\")\n",
    "\n",
    "\n",
    "                else:\n",
    "                    print(f\"Print Failed, response status code {response.status_code}\")\n",
    "            \n",
    "                time.sleep(0.3)\n",
    "\n",
    "\n",
    "            if not 'Season' in combined_playoff_df: #if season is not already a header, then insert\n",
    "                combined_playoff_df.insert(0,'Season',season_var)\n",
    "            if not 'Season' in combined_RS_df:\n",
    "                combined_RS_df.insert(0,'Season',season_var)\n",
    "\n",
    "        playoff_list.append(combined_playoff_df) #we append the newly created dataframes into a list, so that we can concat row-wise for each season. \n",
    "        rs_list.append(combined_RS_df)\n",
    "\n",
    "    reverse_playoff = reversed(playoff_list) #reversing the list, as the list starts with the oldest season, but we usually want to start with the latest season\n",
    "    reverse_rs = reversed(rs_list)\n",
    "    final_playoff_DF = pd.concat(reverse_playoff,axis = 0,ignore_index = True) #concat method will join \"elements\" of the list, in this case the dataframes, row-wise\n",
    "    final_RS_DF = pd.concat(reverse_rs,axis=0,ignore_index = True)\n",
    "    \n",
    "    return final_playoff_DF,final_RS_DF\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "20ca13b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2010-11', '2011-12', '2012-13', '2013-14', '2014-15', '2015-16', '2016-17', '2017-18', '2018-19', '2019-20', '2020-21', '2021-22', '2022-23', '2023-24', '2024-25']\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "playoff_df,RS_df = traditional_stats()\n",
    "\n",
    "\n",
    "\n",
    "playoff_df.to_csv(r\"C:\\Users\\calvin\\Documents\\python\\NBA data analysis project\\nba analysis csv files\\nba_playoffs_traditional_2024-2025.csv\",index = False)\n",
    "RS_df.to_csv(r\"C:\\Users\\calvin\\Documents\\python\\NBA data analysis project\\nba analysis csv files\\nba_regular_season_traditional_2024-2025.csv\",index = False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c6fbfa",
   "metadata": {},
   "source": [
    "#### 1.5 General Stats for x seasons, split into 3 segments  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "21d6a5d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seasons(start_year,current_year):\n",
    "    #this function is to generate a list of seasons \"2024-25\",\"2023-24\",\"2022-23\", etc to pass into our main function\n",
    "    #stats are tracked starting from 1996-97 season\n",
    "    #current_year = \"2025\"\n",
    "    base = int(start_year)\n",
    "    num_years = int(current_year) - base \n",
    "    year_list = []\n",
    "    for i in range(num_years):\n",
    "        season = [f'{base+i}',f'{base+i+1}']\n",
    "        sliced = season[0] + '-' + season[1][2:4]\n",
    "        year_list.append(sliced)\n",
    "    return year_list\n",
    "\n",
    "\n",
    "def traditional_stats():\n",
    "    url = \"https://stats.nba.com/stats/leaguedashteamstats\"\n",
    "    base_params = {\n",
    "        \"Conference\": \"\",\n",
    "        \"DateFrom\":\"\",\n",
    "        \"DateTo\":\"\",\n",
    "        \"Division\":\"\",\n",
    "        \"GameScope\":\"\",\n",
    "        \"GameSegment\":\"\",\n",
    "        \"Height\":\"\",\n",
    "        \"ISTRound\":\"\",\n",
    "        \"LastNGames\":\"0\",\n",
    "        \"LeagueID\":\"00\",\n",
    "        \"Location\":\"\",\n",
    "        \"Month\":\"0\",\n",
    "        \"OpponentTeamID\":\"0\",\n",
    "        \"Outcome\":\"\",\n",
    "        \"PORound\":\"0\",\n",
    "        \"PaceAdjust\":\"N\",\n",
    "        \"PerMode\":\"PerGame\",\n",
    "        \"Period\":\"0\",\n",
    "        \"PlayerExperience\":\"\",\n",
    "        \"PlayerPosition\":\"\",\n",
    "        \"PlusMinus\":\"N\",\n",
    "        \"Rank\":\"N\",\n",
    "        \"Season\":\"2024-25\",\n",
    "        \"ShotClockRange\":\"\",\n",
    "        \"StarterBench\":\"\",\n",
    "        \"TeamID\":\"0\",\n",
    "        \"TwoWay\":\"\",\n",
    "        \"VsConference\":\"\",\n",
    "        \"VsDivision\":\"\",\n",
    "    }\n",
    "    measuretype = ['Base','Advanced','Four Factors','Misc','Scoring','Opponent','Defense',\n",
    "                   'Violations']\n",
    "    cur_seasons = seasons('2010','2025')\n",
    "    season_segment = ['Pre All-Star','Post All-Star','Playoffs']\n",
    "    #Possessions = Touches ##Rebounding, Offensive Rebounding and Defensive Rebounding share the same API URL, unsure how to separate them. \n",
    "\n",
    "    headers = {\n",
    "        \"Host\": \"stats.nba.com\",\n",
    "        \"Connection\": \"keep-alive\",\n",
    "        \"Accept\": \"application/json, text/plain, */*\",\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) \"\n",
    "                    \"AppleWebKit/537.36 (KHTML, like Gecko) \"\n",
    "                    \"Chrome/138.0.0.0 Safari/537.36\",\n",
    "        \"Referer\": \"https://www.nba.com/stats/teams/traditional\",\n",
    "        \"Origin\": \"https://www.nba.com\",\n",
    "        \"Accept-Encoding\": \"gzip, deflate, br\",\n",
    "        \"Accept-Language\": \"en-US,en;q=0.9\"\n",
    "    }\n",
    "\n",
    "    data_list = []\n",
    "\n",
    "    for season_var in cur_seasons: #looping through all seasons from the seasons function. \n",
    "        for segment in season_segment:\n",
    "            combined = pd.DataFrame()\n",
    "\n",
    "            if segment == \"Playoffs\":\n",
    "                season_type = \"Playoffs\"\n",
    "                segment = \"\"\n",
    "            else:\n",
    "                season_type = \"Regular Season\"\n",
    "\n",
    "\n",
    "            for measure_type in measuretype:\n",
    "                param = base_params.copy()\n",
    "                # param['MeasureType'] = measure_type #the column name MUST match the header in the API endpoint\n",
    "                # param['SeasonType'] = season_type\n",
    "                # param['Season'] = season_var\n",
    "                # param['SeasonSegment'] = segment\n",
    "\n",
    "                #another way to do this is to use .update\n",
    "                param.update({\n",
    "                    'MeasureType' : measure_type,\n",
    "                    'SeasonType' : season_type,\n",
    "                    'Season' : season_var,\n",
    "                    'SeasonSegment' : segment\n",
    "                })\n",
    "\n",
    "                response = requests.get(url,params=param,headers=headers) #utilising .get to combine url, params and headers to retrieve information\n",
    "\n",
    "                if response.status_code == 200: #status code 200: http approved the request. other status code can look online\n",
    "                    data = response.json() #to view this data, go to the api endpoint url > response to see the json data \n",
    "                    rows = data['resultSets'][0]['rowSet'] #from the json data, we extract the rows and columns \n",
    "                    headers_ = data['resultSets'][0]['headers']\n",
    "                    \n",
    "                    df = pd.DataFrame(rows,columns = headers_)\n",
    "                    df = df.add_suffix(f\"_{measure_type}\") #adds a suffix to all headers in the dataframe > all headers will have _measuretype\n",
    "                    df = df.rename(columns = {f\"TEAM_NAME_{measure_type}\":\"TEAM_NAME\"}) #maintain the teamname header as the common header, since we will merge on this header\n",
    "\n",
    "                    if combined.empty:\n",
    "                            combined = df\n",
    "                    else:\n",
    "                        df = df.drop(columns=[f'TEAM_ID_{measure_type}',f'GP_{measure_type}',f'W_{measure_type}',\n",
    "                                              f'L_{measure_type}',f'W_PCT_{measure_type}',f'GP_RANK_{measure_type}',f'W_RANK_{measure_type}',\n",
    "                                              f'L_RANK_{measure_type}',f'W_PCT_RANK_{measure_type}'])\n",
    "                        #drop duplicate columns \n",
    "                        combined = pd.merge(combined,df,on = \"TEAM_NAME\",how = \"outer\")\n",
    "                            \n",
    "\n",
    "\n",
    "                else:\n",
    "                    print(f\"Print Failed, response status code {response.status_code}\")\n",
    "            \n",
    "                time.sleep(0.3)\n",
    "\n",
    "\n",
    "            if not 'Season' in combined: #if season is not already a header, then insert\n",
    "                if segment:\n",
    "                    combined.insert(0,'Season',season_var)\n",
    "                    combined.insert(1,'Season Segment',segment)\n",
    "                else:\n",
    "                    combined.insert(0,'Season',season_var)\n",
    "                    combined.insert(1,'Season Segment',\"Playoff\")\n",
    "\n",
    "\n",
    "            data_list.append(combined) #we append the newly created dataframes into a list, so that we can concat row-wise for each season. \n",
    "\n",
    "\n",
    "    # reverse_playoff = reversed(playoff_list) #reversing the list, as the list starts with the oldest season, but we usually want to start with the latest season\n",
    "    # reverse_rs = reversed(rs_list)\n",
    "    reverse_list = reversed(data_list)\n",
    "    final_DF = pd.concat(reverse_list,axis = 0,ignore_index = True) #concat method will join \"elements\" of the list, in this case the dataframes, row-wise\n",
    "    \n",
    "    return final_DF\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "63748be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = traditional_stats()\n",
    "\n",
    "\n",
    "final_df.to_csv(r\"C:\\Users\\calvin\\Documents\\python\\NBA data analysis project\\nba analysis csv files\\nba_general_stats_2024-2025.csv\",index = False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6906145",
   "metadata": {},
   "source": [
    "#### 2.0 Simple Trends/Prediction\n",
    "\n",
    "Now, we have a complete dataset for the \"general\" stats, which consists of common basketball analytical stats that can determine the performance of a team throughout a given period. \n",
    "\n",
    "First, we will define our target columns, and drop any columns that may \"leak\" our data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c15e7a8a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'final_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mre\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m y_data = \u001b[43mfinal_df\u001b[49m[\u001b[33m'\u001b[39m\u001b[33mW_PCT_Base\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m      4\u001b[39m x_data = final_df.filter(regex)\n",
      "\u001b[31mNameError\u001b[39m: name 'final_df' is not defined"
     ]
    }
   ],
   "source": [
    "# import re\n",
    "# y_data = final_df['W_PCT_Base']\n",
    "\n",
    "# for i in range(final_df.shape[1]):\n",
    "#     if 'RANK' in \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba2403f3",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
